# ğŸ“ˆ Forecasting Stock Market Trends  

## ğŸ“Œ Project Overview  
This project focuses on **predicting stock market trends** using machine learning. We analyze historical stock data from major indices (**S&P 500, NASDAQ, DJI, NYSE, Russell 2000**) to forecast closing prices. The project involves **data cleaning, exploratory analysis, feature engineering, and regression modeling** to improve prediction accuracy.  

---

## ğŸ“Š Dataset  
The dataset is sourced from the **UCI Machine Learning Repository** and contains:  
- **Closing Prices**  
- **Trading Volumes**  
- **Volatility Measures**  
- **Stock Indices (S&P 500, NASDAQ, DJI, NYSE, Russell 2000)**  

---

## ğŸ¯ Objective  
Develop a **machine learning model** that predicts stock closing prices based on historical trends and financial indicators.  

---

## ğŸ› ï¸ Data Preprocessing  
âœ” **Handling Missing Values:** Interpolation, forward-fill, and backward-fill techniques.  
âœ” **Outlier Detection:** Z-score method (Threshold = 3).  
âœ” **Feature Scaling:** MinMaxScaler for numerical features.  
âœ” **Feature Encoding:** Encoding categorical variables (e.g., stock indices).  
âœ” **Date Formatting:** Datetime conversion for time-series analysis.  

---

## ğŸ“Š Exploratory Data Analysis (EDA)  
ğŸ” **Time Series Plots:** Visualizing stock trends.  
ğŸ” **Scatter Plots & Cross-Correlation:** Examining relationships between features.  
ğŸ” **Box Plots & Histograms:** Identifying data distributions and anomalies.  
ğŸ” **Heatmaps:** Understanding correlation between features.  

---

## âš™ï¸ Feature Engineering  
ğŸ“Œ **Exponential Moving Averages (EMA_10, EMA_20, EMA_200)** â€“ Capturing short, medium, and long-term trends.  
ğŸ“Œ **Rate of Change (ROC) Indicators** â€“ Measuring momentum shifts.  
ğŸ“Œ **Stock Index Encoding** â€“ Converting categorical indices into numerical values.  

---

## ğŸ¤– Machine Learning Models Used  
We implemented the following **regression models**:  
1. **Linear Regression**  
2. **K-Nearest Neighbors (KNN)**  
3. **Support Vector Machine (SVM)**  
4. **Random Forest**  
5. **Gradient Boosting** *(Best Performing Model)*  

---

## ğŸ”§ Hyperparameter Tuning  
Performed **grid search** for optimal parameters. Best **Gradient Boosting** parameters:  
- **Learning Rate:** 0.1  
- **Number of Estimators:** 100  

---

## ğŸ“ˆ Model Performance Evaluation  
**Metrics Used:**  
âœ” **Mean Squared Error (MSE)**  
âœ” **Root Mean Squared Error (RMSE)**  
âœ” **Mean Absolute Error (MAE)**  
âœ” **R-Squared (RÂ²)**  

| Model | MSE | RMSE | RÂ² |  
|--------|------------|------------|------------|  
| **Linear Regression** | 0.012777 | 0.1129 | 0.85 |  
| **KNN** | 0.024707 | 0.1572 | 0.78 |  
| **Random Forest** | 0.000023 | 0.0048 | **0.9996** |  
| **Gradient Boosting** | **0.000018** | **0.0042** | **0.9998** |  
| **SVM** | 0.006600 | 0.0813 | 0.92 |  
| **SVR** | 0.015817 | 0.1258 | 0.88 |  

---

## ğŸ”¬ Advanced Models & Ensemble Learning  
We explored:  
âœ” **XGBoost** â€“ RÂ²: **0.99956**  
âœ” **Extreme Learning Machine (ELM)** â€“ RÂ²: **0.99909**  
âœ” **Convolutional Neural Networks (CNNs)** â€“ MSE: **5.0370e-05**  
âœ” **Ensemble Model (XGBoost + ELM + CNNs)** â€“ **Best Performing Model**  
   - RÂ²: **0.99976**  
   - MSE: **2.2541e-05**  

---

## ğŸ¯ Conclusion  
âœ” **Gradient Boosting performed best among traditional ML models**.  
âœ” **The ensemble model (XGBoost + ELM + CNN) achieved the highest accuracy**.  
âœ” **Machine learning can effectively forecast stock market trends**.  

---

## ğŸš€ Future Scope  
ğŸ”¹ Exploring **deep learning (LSTMs, Transformers)** for time-series forecasting.  
ğŸ”¹ Implementing **real-time stock prediction pipelines**.  
ğŸ”¹ Using **advanced ensemble techniques (bagging, stacking)** to boost accuracy.  

---
